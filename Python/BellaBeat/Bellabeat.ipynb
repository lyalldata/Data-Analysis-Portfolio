{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process\n",
    " \n",
    " ### Data Cleaning\n",
    " In this phase the data will be uploaded, origanized, cleaned and ready for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful\n"
     ]
    }
   ],
   "source": [
    "# Reading files \n",
    "\n",
    "# Daily Datasets\n",
    "daily_activity  = pd.read_csv(\"/Users/gurilyall/Downloads/Analysis Projects/4. bellabeat_raw_data/csv_files/dailyActivity_merged.csv\")\n",
    "daily_calories   = pd.read_csv(\"/Users/gurilyall/Downloads/Analysis Projects/4. bellabeat_raw_data/csv_files/dailyCalories_merged.csv\")\n",
    "daily_intensities  = pd.read_csv(\"/Users/gurilyall/Downloads/Analysis Projects/4. bellabeat_raw_data/csv_files/dailyIntensities_merged.csv\")\n",
    "daily_steps  = pd.read_csv(\"/Users/gurilyall/Downloads/Analysis Projects/4. bellabeat_raw_data/csv_files/dailySteps_merged.csv\")\n",
    "\n",
    "# Other datasets\n",
    "heartrate_seconds  = pd.read_csv(\"/Users/gurilyall/Downloads/Analysis Projects/4. bellabeat_raw_data/csv_files/heartrate_seconds_merged.csv\")\n",
    "sleep_log  = pd.read_csv(\"/Users/gurilyall/Downloads/Analysis Projects/4. bellabeat_raw_data/csv_files/sleepDay_merged.csv\")\n",
    "weight_log  = pd.read_csv(\"/Users/gurilyall/Downloads/Analysis Projects/4. bellabeat_raw_data/csv_files/weightLogInfo_merged.csv\")\n",
    "print(\"successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Activity\n",
      " Index(['Id', 'ActivityDate', 'TotalSteps', 'TotalDistance', 'TrackerDistance',\n",
      "       'LoggedActivitiesDistance', 'VeryActiveDistance',\n",
      "       'ModeratelyActiveDistance', 'LightActiveDistance',\n",
      "       'SedentaryActiveDistance', 'VeryActiveMinutes', 'FairlyActiveMinutes',\n",
      "       'LightlyActiveMinutes', 'SedentaryMinutes', 'Calories'],\n",
      "      dtype='object') \n",
      "\n",
      "Daily Calories\n",
      " Index(['Id', 'ActivityDay', 'Calories'], dtype='object') \n",
      "\n",
      "Daily Intensities\n",
      " Index(['Id', 'ActivityDay', 'SedentaryMinutes', 'LightlyActiveMinutes',\n",
      "       'FairlyActiveMinutes', 'VeryActiveMinutes', 'SedentaryActiveDistance',\n",
      "       'LightActiveDistance', 'ModeratelyActiveDistance',\n",
      "       'VeryActiveDistance'],\n",
      "      dtype='object') \n",
      "\n",
      "Daily Steps\n",
      " Index(['Id', 'ActivityDay', 'StepTotal'], dtype='object') \n",
      "\n",
      "Heart Rate\n",
      " Index(['Id', 'Time', 'Value'], dtype='object') \n",
      "\n",
      "Sleep Log\n",
      " Index(['Id', 'SleepDay', 'TotalSleepRecords', 'TotalMinutesAsleep',\n",
      "       'TotalTimeInBed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Checking column names of all the dataframes\n",
    "\n",
    "print(\"Daily Activity\\n\",daily_activity.columns,\n",
    "      \"\\n\\nDaily Calories\\n\",daily_calories.columns,\n",
    "      \"\\n\\nDaily Intensities\\n\",daily_intensities.columns,\n",
    "      \"\\n\\nDaily Steps\\n\",daily_steps.columns,\n",
    "      \"\\n\\nHeart Rate\\n\",heartrate_seconds.columns,\n",
    "      \"\\n\\nSleep Log\\n\",sleep_log.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets check the size, shape & datatypes of all the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity Size: 14100 \n",
      "activity Shape: (940, 15) \n",
      "Data types:\n",
      " Id                            int64\n",
      "ActivityDate                 object\n",
      "TotalSteps                    int64\n",
      "TotalDistance               float64\n",
      "TrackerDistance             float64\n",
      "LoggedActivitiesDistance    float64\n",
      "VeryActiveDistance          float64\n",
      "ModeratelyActiveDistance    float64\n",
      "LightActiveDistance         float64\n",
      "SedentaryActiveDistance     float64\n",
      "VeryActiveMinutes             int64\n",
      "FairlyActiveMinutes           int64\n",
      "LightlyActiveMinutes          int64\n",
      "SedentaryMinutes              int64\n",
      "Calories                      int64\n",
      "dtype: object\n",
      "--------------------------------------------------\n",
      "Calories Size: 2820 \n",
      "calories Shape: (940, 3) \n",
      "Data types:\n",
      " Id              int64\n",
      "ActivityDay    object\n",
      "Calories        int64\n",
      "dtype: object\n",
      "--------------------------------------------------\n",
      "Data Intensities Size: 9400 \n",
      "data Shape: (940, 10) \n",
      "Data types:\n",
      " Id                            int64\n",
      "ActivityDay                  object\n",
      "SedentaryMinutes              int64\n",
      "LightlyActiveMinutes          int64\n",
      "FairlyActiveMinutes           int64\n",
      "VeryActiveMinutes             int64\n",
      "SedentaryActiveDistance     float64\n",
      "LightActiveDistance         float64\n",
      "ModeratelyActiveDistance    float64\n",
      "VeryActiveDistance          float64\n",
      "dtype: object\n",
      "--------------------------------------------------\n",
      "Steps Size: 2820 \n",
      "steps Shape: (940, 3) \n",
      "Data types:\n",
      " Id              int64\n",
      "ActivityDay    object\n",
      "StepTotal       int64\n",
      "dtype: object\n",
      "--------------------------------------------------\n",
      "Heart Rate Size: 7450974 \n",
      "Heart Rate Shape: (2483658, 3) \n",
      "Data types:\n",
      " Id        int64\n",
      "Time     object\n",
      "Value     int64\n",
      "dtype: object\n",
      "--------------------------------------------------\n",
      "Sleep Log Size: 2065 \n",
      "Sleep Log Shape: (413, 5) \n",
      "Data types:\n",
      " Id                     int64\n",
      "SleepDay              object\n",
      "TotalSleepRecords      int64\n",
      "TotalMinutesAsleep     int64\n",
      "TotalTimeInBed         int64\n",
      "dtype: object\n",
      "--------------------------------------------------\n",
      "Weight Log Size: 536 \n",
      "Weight Log Shape: (67, 8) \n",
      "Data types:\n",
      " Id                  int64\n",
      "Date               object\n",
      "WeightKg          float64\n",
      "WeightPounds      float64\n",
      "Fat               float64\n",
      "BMI               float64\n",
      "IsManualReport       bool\n",
      "LogId               int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# checking data shape, size and data types\n",
    "print('Activity Size:', daily_activity.size, \n",
    "      \"\\nactivity Shape:\" , daily_activity.shape, \n",
    "      '\\nData types:\\n',daily_activity.dtypes )\n",
    "\n",
    "print(f'{\"-\"*50}\\nCalories Size:', daily_calories.size, \n",
    "      \"\\ncalories Shape:\" , daily_calories.shape, \n",
    "      '\\nData types:\\n',daily_calories.dtypes )\n",
    "\n",
    "print(f'{\"-\"*50}\\nData Intensities Size:', daily_intensities.size, \n",
    "      \"\\ndata Shape:\" , daily_intensities.shape, \n",
    "      '\\nData types:\\n',daily_intensities.dtypes )\n",
    "\n",
    "print(f'{\"-\"*50}\\nSteps Size:', daily_steps.size, \n",
    "      \"\\nsteps Shape:\" , daily_steps.shape, \n",
    "      '\\nData types:\\n',daily_steps.dtypes )\n",
    "\n",
    "print(f'{\"-\"*50}\\nHeart Rate Size:', heartrate_seconds.size,\n",
    "      \"\\nHeart Rate Shape:\", heartrate_seconds.shape,\n",
    "      '\\nData types:\\n',heartrate_seconds.dtypes )\n",
    "\n",
    "print(f'{\"-\"*50}\\nSleep Log Size:', sleep_log.size,\n",
    "      \"\\nSleep Log Shape:\", sleep_log.shape,\n",
    "      '\\nData types:\\n',sleep_log.dtypes )\n",
    "\n",
    "print(f'{\"-\"*50}\\nWeight Log Size:', weight_log.size,\n",
    "      \"\\nWeight Log Shape:\", weight_log.shape,\n",
    "      '\\nData types:\\n',weight_log.dtypes )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will count the total number of participants by their unique IDs and analyze the frequency of their participation. By checking the value counts, we can assess the level of engagement and determine whether participants were actively involved in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily_activity Participants: 33 \n",
      "daily_calories Participants: 33 \n",
      "daily_intensities Participants: 33 \n",
      "daily_steps Participants: 33 \n",
      "Heart Rate Participants: 14 \n",
      "Sleep Log Participants: 24 \n",
      "Weight Log Participants: 8\n"
     ]
    }
   ],
   "source": [
    "# checking the number of participants in each dataset\n",
    "print(\"daily_activity Participants:\", daily_activity.Id.nunique(),\n",
    "      \"\\ndaily_calories Participants:\", daily_calories.Id.nunique(),\n",
    "      \"\\ndaily_intensities Participants:\", daily_intensities.Id.nunique(),\n",
    "      \"\\ndaily_steps Participants:\", daily_steps.Id.nunique(),\n",
    "      \"\\nHeart Rate Participants:\", heartrate_seconds.Id.nunique(),\n",
    "      \"\\nSleep Log Participants:\", sleep_log.Id.nunique(),\n",
    "      \"\\nWeight Log Participants:\", weight_log.Id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows, `Sleep Log`,`Heart Rate` and `weight_log` have `24`,`14`,`8`  different participants log-ins . All the other datasets have `33`  log-ins from 33 participants.\n",
    "\n",
    "In the next step we will check the amounts of logins per dataset to check the participation of each person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Login(s) for each participant by ID\n",
      "\n",
      "             Activity  Calories  Intensities  Steps  Heartrate  SleepLog  WeightLog\n",
      "Id                                                                                \n",
      "1503960366        31        31           31     31        NaN      25.0        2.0\n",
      "4319703577        31        31           31     31        NaN      26.0        2.0\n",
      "8583815059        31        31           31     31        NaN       NaN        NaN\n",
      "8378563200        31        31           31     31        NaN      32.0        NaN\n",
      "8053475328        31        31           31     31        NaN       3.0        NaN\n",
      "7086361926        31        31           31     31        NaN      24.0        NaN\n",
      "6962181067        31        31           31     31   266326.0      31.0       30.0\n",
      "5553957443        31        31           31     31   255174.0      31.0        NaN\n",
      "4702921684        31        31           31     31        NaN      28.0        NaN\n",
      "4558609924        31        31           31     31   192168.0       5.0        5.0\n",
      "1624580081        31        31           31     31        NaN       NaN        NaN\n",
      "4388161847        31        31           31     31   249748.0      24.0        NaN\n",
      "4445114986        31        31           31     31        NaN      28.0        NaN\n",
      "8877689391        31        31           31     31   228841.0       NaN       24.0\n",
      "1927972279        31        31           31     31        NaN       5.0        1.0\n",
      "2873212765        31        31           31     31        NaN       NaN        2.0\n",
      "2320127002        31        31           31     31        NaN       1.0        NaN\n",
      "4020332650        31        31           31     31   285461.0       8.0        NaN\n",
      "2026352035        31        31           31     31     2490.0      28.0        NaN\n",
      "1844505072        31        31           31     31        NaN       3.0        NaN\n",
      "2022484408        31        31           31     31   154104.0       NaN        NaN\n",
      "3977333714        30        30           30     30        NaN      28.0        NaN\n",
      "1644430081        30        30           30     30        NaN       4.0        NaN\n",
      "5577150313        30        30           30     30   248560.0      26.0        1.0\n",
      "8792009665        29        29           29     29   122841.0      15.0        NaN\n",
      "6290855005        29        29           29     29        NaN       NaN        NaN\n",
      "6117666160        28        28           28     28   158899.0      18.0        NaN\n",
      "6775888955        26        26           26     26    32771.0       3.0        NaN\n",
      "7007744171        26        26           26     26   133592.0       2.0        NaN\n",
      "3372868164        20        20           20     20        NaN       NaN        NaN\n",
      "8253242879        19        19           19     19        NaN       NaN        NaN\n",
      "2347167796        18        18           18     18   152683.0      15.0        NaN\n",
      "4057192912         4         4            4      4        NaN       NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.width', 1000)  \n",
    "pd.set_option('display.max_columns', None)  \n",
    "# checking login(s) for each participant by ID\n",
    "\n",
    "comparison = pd.concat([\n",
    "    daily_activity['Id'].value_counts().rename('Activity'),\n",
    "    daily_calories['Id'].value_counts().rename('Calories'),\n",
    "    daily_intensities['Id'].value_counts().rename('Intensities'),\n",
    "    daily_steps['Id'].value_counts().rename('Steps'),\n",
    "    heartrate_seconds['Id'].value_counts().rename('Heartrate'),\n",
    "    sleep_log['Id'].value_counts().rename('SleepLog'),\n",
    "    weight_log['Id'].value_counts().rename('WeightLog')\n",
    "], axis=1)\n",
    "\n",
    "print(f\"{\" \"*20}Login(s) for each participant by ID\\n\\n\",comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the daily datasets the particpation is good  except 1 women with `4` entries. Fewer number of women participated in heartrate_seconds, Sleep_log, weight_log according to that there are alot of `Nan`s in these 3 datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we are examining all the datasets to identify any missing data. This helps us understand the completeness of the datasets and determine how to handle any gaps or inconsistencies in the data moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily_activity Missing Values: 0 \n",
      "daily_calories Missing Values: 0 \n",
      "daily_intensities Missing Values: 0 \n",
      "daily_steps Missing Values: 0 \n",
      "Heart Rate Missing Values: 0 \n",
      "Sleep Log Missing Values: 0 \n",
      "Weight Log Missing Values: 65\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values in each dataset\n",
    "print(\"daily_activity Missing Values:\", daily_activity.isnull().sum().sum(),  \n",
    "      \"\\ndaily_calories Missing Values:\", daily_calories.isnull().sum().sum(),  \n",
    "      \"\\ndaily_intensities Missing Values:\", daily_intensities.isnull().sum().sum(),  \n",
    "      \"\\ndaily_steps Missing Values:\", daily_steps.isnull().sum().sum(),  \n",
    "      \"\\nHeart Rate Missing Values:\", heartrate_seconds.isnull().sum().sum(),  \n",
    "      \"\\nSleep Log Missing Values:\", sleep_log.isnull().sum().sum(),\n",
    "      \"\\nWeight Log Missing Values:\", weight_log.isnull().sum().sum())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 0\n",
       "Date               0\n",
       "WeightKg           0\n",
       "WeightPounds       0\n",
       "Fat               65\n",
       "BMI                0\n",
       "IsManualReport     0\n",
       "LogId              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_log.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight_log dataset contains `67` rows of data, with `65` of them having null values in the `Fat` column. This indicates that most of the data is missing, limiting the insights that can be drawn from the Fat column. Meanwhile, this issue has been forwarded to the Marketing Analysis Team and Bellabeatâ€™s IT Team for further investigation. We will not drop the data and will continue with the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for Duplicated entries in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily_activity Duplicates: 0 \n",
      "daily_calories Duplicates: 0 \n",
      "daily_intensities Duplicates: 0 \n",
      "daily_steps Duplicates: 0 \n",
      "Heart Rate Duplicates: 0 \n",
      "Sleep Log Duplicates: 3 \n",
      "Weight Log Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# checking for duplicates\n",
    "print(\"daily_activity Duplicates:\", daily_activity.duplicated().sum(),  \n",
    "      \"\\ndaily_calories Duplicates:\", daily_calories.duplicated().sum(),  \n",
    "      \"\\ndaily_intensities Duplicates:\", daily_intensities.duplicated().sum(),  \n",
    "      \"\\ndaily_steps Duplicates:\", daily_steps.duplicated().sum(),  \n",
    "      \"\\nHeart Rate Duplicates:\", heartrate_seconds.duplicated().sum(),  \n",
    "      \"\\nSleep Log Duplicates:\", sleep_log.duplicated().sum(),\n",
    "      \"\\nWeight Log Duplicates:\", weight_log.duplicated().sum())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the output there are `3` duplicated entries in the sleep log dataset. In the next step, dropping the duplicated values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleep Log Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# dropping duplicated and null data entries\n",
    "sleep_log.drop_duplicates(inplace=True)\n",
    "print(\"Sleep Log Duplicates:\", sleep_log.duplicated().sum())  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze\n",
    "\n",
    "### Data Transformation\n",
    "In this Phase, we will transform the data using various methods, such as changing data types, renaming columns, merging datasets, and creating new columns or aliases. These changes will be made in a way that preserves the original data, allowing it to be accessed or reviewed if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the columns\n",
    "daily_activity = daily_activity.rename(columns = {'ActivityDate':'ActivityDay'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data:  0 \n",
      "Dataset Shape:  (940, 25) \n",
      "Dataset Size:  23500\n"
     ]
    }
   ],
   "source": [
    "# mering all the daily datasets into one\n",
    "df1 = pd.merge(pd.merge(pd.merge(daily_activity, daily_calories, on=['Id', 'ActivityDay'], how='outer'), daily_intensities, on=['Id', 'ActivityDay'], how='outer'), daily_steps, on=['Id', 'ActivityDay'], how='outer')\n",
    "\n",
    "print(\"Missing Data: \",df1.isnull().sum().sum(),\n",
    "      \"\\nDataset Shape: \", df1.shape,\n",
    "      \"\\nDataset Size: \", df1.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset shape indicates `940` rows and `25` columns, which aligns with the combined total from the initial four datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the format of the of all the date for all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Dataset datetime64[ns] \n",
      "Heart Rate Dataset datetime64[ns] \n",
      "Weight Log Dataset datetime64[ns] \n",
      "Sleep Log Dataset datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Daily dataset date formatting\n",
    "df1['ActivityDay'] = pd.to_datetime(df1['ActivityDay'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# Heart rate dataset date and time formatting\n",
    "heart = heartrate_seconds.copy()\n",
    "heart['Date'] = pd.to_datetime(heart['Time'], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "\n",
    "# Weight log dataset date formatting\n",
    "weight = weight_log.copy()\n",
    "weight['Date'] = pd.to_datetime(weight['Date'], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "\n",
    "# Sleep log dataset date formatting\n",
    "sleep = sleep_log.copy()\n",
    "sleep['SleepDay'] = pd.to_datetime(sleep['SleepDay'], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "\n",
    "print(\"Daily Dataset\", df1['ActivityDay'].dtype,\n",
    "      \"\\nHeart Rate Dataset\", heart['Date'].dtype,\n",
    "      \"\\nWeight Log Dataset\", weight['Date'].dtype,\n",
    "      \"\\nSleep Log Dataset\", sleep['SleepDay'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a copy to work with, so the original data available as a back-up. Creating a new column `DayOfTheWeek` by extrating data from the `ActivityDay`. With the data available for 2 month `DayOfTheWeek` would help to understand the pattern of the fitbit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DayOfTheWeek\n",
       "Tuesday      452381\n",
       "Wednesday    399232\n",
       "Thursday     359146\n",
       "Friday       357594\n",
       "Saturday     338394\n",
       "Monday       289764\n",
       "Sunday       287147\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reindex function to rearrange the data\n",
    "df_2= df1.copy()\n",
    "\n",
    "# print 1st 5 rows to confirm\n",
    "df_2['DayOfTheWeek'] = df_2['ActivityDay'].dt.day_name()\n",
    "df_2.DayOfTheWeek.value_counts()\n",
    "# df_2.info()\n",
    "\n",
    "heart['DayOfTheWeek'] = heart['Date'].dt.day_name()\n",
    "heart.DayOfTheWeek.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save time when checking each row and column for duplicates, a function called check_columns_match was developed. This function compares data at each index for columns with the same name. To keep the process simple, columns ending with `_x` were assigned to the `x` variable, while those ending with `_y` were assigned to the `y` variable.\n",
    "\n",
    "\n",
    "The function outputs whether the columns match or mismatch. If the data matches, the duplicate column will be dropped to reduce redundancy. Just to make sure the function is working properly  2 different columns were added to the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: All values in columns 'VeryActiveMinutes_x' and 'VeryActiveMinutes_y' are the same.\n",
      "Match: All values in columns 'FairlyActiveMinutes_x' and 'FairlyActiveMinutes_y' are the same.\n",
      "Match: All values in columns 'LightlyActiveMinutes_x' and 'LightlyActiveMinutes_y' are the same.\n",
      "Match: All values in columns 'SedentaryMinutes_x' and 'SedentaryMinutes_y' are the same.\n",
      "Match: All values in columns 'VeryActiveDistance_x' and 'VeryActiveDistance_y' are the same.\n",
      "Match: All values in columns 'ModeratelyActiveDistance_x' and 'ModeratelyActiveDistance_y' are the same.\n",
      "Match: All values in columns 'LightActiveDistance_x' and 'LightActiveDistance_y' are the same.\n",
      "Match: All values in columns 'SedentaryActiveDistance_x' and 'SedentaryActiveDistance_y' are the same.\n",
      "Match: All values in columns 'Calories_x' and 'Calories_y' are the same.\n",
      "Match: All values in columns 'TotalSteps' and 'StepTotal' are the same.\n",
      "\n",
      "Mismatch in columns 'TotalSteps' and 'TrackerDistance' at index 0\n",
      "Mismatch: Not all values in columns 'TotalSteps' and 'TrackerDistance' are the same.\n"
     ]
    }
   ],
   "source": [
    "# to check if the data in these columns are same \n",
    "x = ['VeryActiveMinutes_x', 'FairlyActiveMinutes_x', 'LightlyActiveMinutes_x', 'SedentaryMinutes_x','VeryActiveDistance_x', 'ModeratelyActiveDistance_x', 'LightActiveDistance_x', 'SedentaryActiveDistance_x', 'Calories_x','TotalSteps','TotalSteps']\n",
    "y = ['VeryActiveMinutes_y', 'FairlyActiveMinutes_y', 'LightlyActiveMinutes_y', 'SedentaryMinutes_y','VeryActiveDistance_y', 'ModeratelyActiveDistance_y', 'LightActiveDistance_y', 'SedentaryActiveDistance_y', 'Calories_y','StepTotal','TrackerDistance']\n",
    "    \n",
    "\n",
    "def check_columns_match(df, col_x_list, col_y_list):\n",
    "    for col_x, col_y in zip(col_x_list, col_y_list):\n",
    "        match = True\n",
    "        for i in range(len(df)):\n",
    "            if df[col_x][i] != df[col_y][i]:\n",
    "                match = False\n",
    "                print(f\"\\nMismatch in columns '{col_x}' and '{col_y}' at index {i}\")\n",
    "                break\n",
    "\n",
    "        if match:\n",
    "            print(f\"Match: All values in columns '{col_x}' and '{col_y}' are the same.\")\n",
    "        else:\n",
    "            print(f\"Mismatch: Not all values in columns '{col_x}' and '{col_y}' are the same.\")\n",
    "\n",
    "\n",
    "check_columns_match(df_2, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All columns in the `x` variable `match` with those in the `y`. Therefore, to improve efficiency and reduce redundancy, all columns ending with `_y` will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 940 entries, 0 to 939\n",
      "Data columns (total 16 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   Id                          940 non-null    int64         \n",
      " 1   ActivityDay                 940 non-null    datetime64[ns]\n",
      " 2   TotalSteps                  940 non-null    int64         \n",
      " 3   TotalDistance               940 non-null    float64       \n",
      " 4   TrackerDistance             940 non-null    float64       \n",
      " 5   LoggedActivitiesDistance    940 non-null    float64       \n",
      " 6   VeryActiveDistance_x        940 non-null    float64       \n",
      " 7   ModeratelyActiveDistance_x  940 non-null    float64       \n",
      " 8   LightActiveDistance_x       940 non-null    float64       \n",
      " 9   SedentaryActiveDistance_x   940 non-null    float64       \n",
      " 10  VeryActiveMinutes_x         940 non-null    int64         \n",
      " 11  FairlyActiveMinutes_x       940 non-null    int64         \n",
      " 12  LightlyActiveMinutes_x      940 non-null    int64         \n",
      " 13  SedentaryMinutes_x          940 non-null    int64         \n",
      " 14  Calories_x                  940 non-null    int64         \n",
      " 15  DayOfTheWeek                940 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(7), int64(7), object(1)\n",
      "memory usage: 117.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# deleting duplicate columns\n",
    "df_2 = df_2.drop(columns = ['VeryActiveMinutes_y', 'FairlyActiveMinutes_y', 'LightlyActiveMinutes_y', 'SedentaryMinutes_y', \n",
    "        'VeryActiveDistance_y', 'ModeratelyActiveDistance_y', 'LightActiveDistance_y', 'SedentaryActiveDistance_y', 'Calories_y','StepTotal'])\n",
    "df_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created a new column, `total_mins` & `total_hours`, to aggregate the total time spent across all activity phases, providing a comprehensive view of the overall activity duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_mins</th>\n",
       "      <th>total_hours</th>\n",
       "      <th>DayOfTheWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1094</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1033</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1440</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>998</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1040</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>761</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1440</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1120</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1063</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1076</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_mins  total_hours DayOfTheWeek\n",
       "0        1094         18.0      Tuesday\n",
       "1        1033         17.0    Wednesday\n",
       "2        1440         24.0     Thursday\n",
       "3         998         17.0       Friday\n",
       "4        1040         17.0     Saturday\n",
       "5         761         13.0       Sunday\n",
       "6        1440         24.0       Monday\n",
       "7        1120         19.0      Tuesday\n",
       "8        1063         18.0    Wednesday\n",
       "9        1076         18.0     Thursday"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total mins column\n",
    "df_2['total_mins'] = df_2['VeryActiveMinutes_x'] + df_2['FairlyActiveMinutes_x'] + df_2['LightlyActiveMinutes_x'] + df_2['SedentaryMinutes_x'] \n",
    "\n",
    "#total hours column\n",
    "df_2['total_hours'] =round(df_2['total_mins']/60)\n",
    "\n",
    "df_2[['total_mins','total_hours','DayOfTheWeek']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating new column in the sleep dataset to check the awake time in bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Participants: 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SleepDay</th>\n",
       "      <th>TotalSleepRecords</th>\n",
       "      <th>TotalMinutesAsleep</th>\n",
       "      <th>TotalTimeInBed</th>\n",
       "      <th>inBed_awake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1503960366</td>\n",
       "      <td>2016-04-12</td>\n",
       "      <td>1</td>\n",
       "      <td>327</td>\n",
       "      <td>346</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1503960366</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>2</td>\n",
       "      <td>384</td>\n",
       "      <td>407</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1503960366</td>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>1</td>\n",
       "      <td>412</td>\n",
       "      <td>442</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1503960366</td>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>2</td>\n",
       "      <td>340</td>\n",
       "      <td>367</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1503960366</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>712</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id   SleepDay  TotalSleepRecords  TotalMinutesAsleep  TotalTimeInBed  inBed_awake\n",
       "0  1503960366 2016-04-12                  1                 327             346           19\n",
       "1  1503960366 2016-04-13                  2                 384             407           23\n",
       "2  1503960366 2016-04-15                  1                 412             442           30\n",
       "3  1503960366 2016-04-16                  2                 340             367           27\n",
       "4  1503960366 2016-04-17                  1                 700             712           12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep['inBed_awake'] = sleep.TotalTimeInBed - sleep.TotalMinutesAsleep\n",
    "\n",
    "print(\"Total Participants:\", sleep.Id.nunique())\n",
    "sleep.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking mean awake time in bed by Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>mean_inBed_awake</th>\n",
       "      <th>mean_sleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1503960366</td>\n",
       "      <td>22.92</td>\n",
       "      <td>360.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1644430081</td>\n",
       "      <td>52.00</td>\n",
       "      <td>294.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1844505072</td>\n",
       "      <td>309.00</td>\n",
       "      <td>652.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1927972279</td>\n",
       "      <td>20.80</td>\n",
       "      <td>417.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  mean_inBed_awake  mean_sleep\n",
       "0  1503960366             22.92      360.28\n",
       "1  1644430081             52.00      294.00\n",
       "2  1844505072            309.00      652.00\n",
       "3  1927972279             20.80      417.00"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking mean sleep and awake time for each id\n",
    "awake_mean_df = sleep[[\"Id\",\"inBed_awake\",\"TotalMinutesAsleep\"]]\n",
    "\n",
    "awake_mean = awake_mean_df.groupby(\"Id\")['inBed_awake'].mean().reset_index()\n",
    "sleep_mean = awake_mean_df.groupby(\"Id\")['TotalMinutesAsleep'].mean().reset_index()\n",
    "\n",
    "sleep_mean_df = pd.merge(awake_mean, sleep_mean, on=\"Id\")\n",
    "\n",
    "sleep_mean_df.columns = [\"Id\",\"mean_inBed_awake\",\"mean_sleep\"]\n",
    "sleep_mean_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the weight dataset, a new column Month was created to separate the data by month, allowing for a more detailed analysis of variations in the weightKg column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April Id count 5 \n",
      "May Id count 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract the month from the 'Date' column and create a new 'Month' column\n",
    "weight['Month'] = weight['Date'].dt.month\n",
    "weight.Month.head()\n",
    "\n",
    "april_raw = weight[weight['Month'] == 4]\n",
    "may_raw = weight[weight['Month'] == 5]\n",
    "\n",
    "# print(april['Id'].unique())\n",
    "# print(may['Id'].unique())\n",
    "\n",
    "april = april_raw[april_raw['Id'].isin(may_raw['Id'])]  # Full rows from April\n",
    "may = may_raw[may_raw['Id'].isin(april_raw['Id'])] \n",
    "print('April Id count',april.Id.nunique(),\n",
    "        '\\nMay Id count',may.Id.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           April                   May           \n",
      "             BMI   WeightKg        BMI   WeightKg\n",
      "count  38.000000  38.000000  25.000000  25.000000\n",
      "mean   24.847895  72.118422  24.894000  70.260000\n",
      "std     1.170937  11.639561   1.340469  10.841549\n",
      "min    21.450001  56.700001  21.690001  57.299999\n",
      "25%    23.969999  61.425001  24.000000  61.500000\n",
      "50%    24.840000  66.099998  24.350000  62.400002\n",
      "75%    25.559999  85.099998  25.559999  84.400002\n",
      "max    27.459999  85.800003  27.379999  85.500000\n"
     ]
    }
   ],
   "source": [
    "april_stats = april[[\"BMI\", \"WeightKg\"]].describe()\n",
    "may_stats = may[[\"BMI\", \"WeightKg\"]].describe()\n",
    "\n",
    "# Combine side by side for comparison\n",
    "comparison = pd.concat([april_stats, may_stats], axis=1, keys=['April', 'May'])\n",
    "\n",
    "# Display result\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going in depth to check if any  change occured in the of the participating women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            April_BMI   WeightKg    May_BMI   WeightKg\n",
      "Id                                                    \n",
      "2873212765  21.450001  56.700001  21.690001  57.299999\n",
      "4319703577  27.450001  72.400002  27.379999  72.300003\n",
      "4558609924  27.355000  70.000000  27.120000  69.399999\n",
      "6962181067  24.023888  61.544445  24.034167  61.566667\n",
      "8877689391  25.511250  85.225001  25.438750  84.987501\n"
     ]
    }
   ],
   "source": [
    "# Checking weight and BMI for each id for April and May\n",
    "april_stats = april.groupby('Id')[[\"BMI\", \"WeightKg\"]].mean().rename(columns={'BMI': 'April_BMI'})\n",
    "may_stats = may.groupby('Id')[[\"BMI\", \"WeightKg\"]].mean().rename(columns={'BMI': 'May_BMI'})\n",
    "\n",
    "combined_stats = pd.concat([april_stats, may_stats], axis=1)\n",
    "\n",
    "# Display the combined stats\n",
    "print(combined_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the two-month period of data collection, the weight dataset shows minimal variation in BMI and weight statistics across participants, indicating largely consistent results throughout the period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fucntion for day count\n",
    "def count_day(day_of_week):\n",
    "    count = 0\n",
    "    for day in df_2.DayOfTheWeek:\n",
    "        if day == day_of_week:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "Mon = count_day(\"Monday\")\n",
    "Tue = count_day(\"Tuesday\")\n",
    "Wed = count_day(\"Wednesday\")\n",
    "Thu = count_day(\"Thursday\")\n",
    "Fri = count_day(\"Friday\")\n",
    "Sat = count_day(\"Saturday\")\n",
    "Sun = count_day(\"Sunday\")\n",
    "\n",
    "# mean stats \n",
    "mean_calories = df_2.Calories_x.mean()\n",
    "mean_hours = df_2.total_hours.mean()\n",
    "mean_sedentary = df_2.SedentaryMinutes_x.mean()/60 # converting to minutes\n",
    "mean_light =df_2. LightlyActiveMinutes_x.mean()/60 # converting to minutes\n",
    "mean_fairlyActive = df_2.FairlyActiveMinutes_x.mean()\n",
    "mean_V_active = (df_2.VeryActiveMinutes_x.mean()/60)\n",
    "\n",
    "#mean distance stats\n",
    "mean_calories = round(df_2.Calories_x.mean(),2)\n",
    "mean_distance = round(df_2.TotalDistance.mean(),2)\n",
    "mean_sedentary_d = round(df_2.SedentaryActiveDistance_x.mean(),2)\n",
    "mean_light_d =  round(df_2.LightActiveDistance_x.mean(),2) \n",
    "mean_moderate_d = round(df_2.ModeratelyActiveDistance_x.mean(),2)\n",
    "mean_V_active_d = round(df_2.VeryActiveDistance_x.mean(),2)\n",
    "mean_logged_d =round(df_2.LoggedActivitiesDistance.mean(),2)\n",
    "mean_tracker_d = round(df_2.TrackerDistance.mean(),2)\n",
    "\n",
    "# mean  step stats\n",
    "mean_steps =round(df_2.TotalSteps.mean())\n",
    "mean_distance = round(df_2.TotalDistance.mean())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
